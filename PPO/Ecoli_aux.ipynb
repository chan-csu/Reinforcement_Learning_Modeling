{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of amino acid knockout on auxotrophic Ecoli communities\n",
    "\n",
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from mimetypes import init\n",
    "from turtle import color\n",
    "import Toolkit as tk\n",
    "import torch\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import ray\n",
    "import os\n",
    "import seaborn  as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import rich\n",
    "NUM_CORES = mp.cpu_count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Ecoli GEMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "model_base=cobra.io.read_sbml_model(\"iAF1260.xml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the minimal growth medium that is included with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium=model_base.medium.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find aa necessary reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model=model_base.copy()\n",
    "knockouts_gene_names=[\"serA\",\"glyA\",\"cysE\",\"metA\",\"thrC\",\"ilvA\",\"trpC\",\"pheA\",\"tyrA\",\"hisB\",\"proA\",\"argA\",\"leuB\"]\n",
    "gene_ids={}\n",
    "for ko_gene in knockouts_gene_names:\n",
    "    for gene in test_model.genes:\n",
    "        if gene.name==ko_gene:\n",
    "            gene_ids[ko_gene]=gene.id\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchane_reactions={\n",
    "    \"serA\": \"EX_ser__L_e\",\n",
    "    \"glyA\": \"EX_gly_e\",\n",
    "    \"cysE\": \"EX_cys__L_e\",\n",
    "    \"metA\": \"EX_met__L_e\",\n",
    "    \"thrC\": \"EX_thr__L_e\",\n",
    "    \"ilvA\": \"EX_ile__L_e\",\n",
    "    \"trpC\": \"EX_trp__L_e\",\n",
    "    \"pheA\": \"EX_phe__L_e\",\n",
    "    \"tyrA\": \"EX_tyr__L_e\",\n",
    "    \"hisB\": \"EX_his__L_e\",\n",
    "    \"proA\": \"EX_pro__L_e\",\n",
    "    \"argA\": \"EX_arg__L_e\",\n",
    "    \"leuB\": \"EX_leu__L_e\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange_mets={}\n",
    "for i in exchane_reactions.items():\n",
    "    exchange_mets[i[0]]=list(test_model.reactions.get_by_id(i[1]).metabolites.keys())[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serA': 'ser__L_e',\n",
       " 'glyA': 'gly_e',\n",
       " 'cysE': 'cys__L_e',\n",
       " 'metA': 'met__L_e',\n",
       " 'thrC': 'thr__L_e',\n",
       " 'ilvA': 'ile__L_e',\n",
       " 'trpC': 'trp__L_e',\n",
       " 'pheA': 'phe__L_e',\n",
       " 'tyrA': 'tyr__L_e',\n",
       " 'hisB': 'his__L_e',\n",
       " 'proA': 'pro__L_e',\n",
       " 'argA': 'arg__L_e',\n",
       " 'leuB': 'leu__L_e'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_mets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td><strong>Reaction identifier</strong></td><td>PGCD</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Name</strong></td><td>Phosphoglycerate dehydrogenase</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Memory address</strong></td>\n",
       "                <td>0x16c8affd0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Stoichiometry</strong></td>\n",
       "                <td>\n",
       "                    <p style='text-align:right'>3pg_c + nad_c --> 3php_c + h_c + nadh_c</p>\n",
       "                    <p style='text-align:right'>3-Phospho-D-glycerate + Nicotinamide adenine dinucleotide --> 3-Phosphohydroxypyruvate + H+ + Nicotinamide adenine dinucleotide - reduced</p>\n",
       "                </td>\n",
       "            </tr><tr>\n",
       "                <td><strong>GPR</strong></td><td>b2913</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Lower bound</strong></td><td>0.0</td>\n",
       "            </tr><tr>\n",
       "                <td><strong>Upper bound</strong></td><td>999999.0</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<Reaction PGCD at 0x16c8affd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.reactions.get_by_id(\"PGCD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serA': 'b2913',\n",
       " 'glyA': 'b2551',\n",
       " 'cysE': 'b3607',\n",
       " 'metA': 'b4013',\n",
       " 'thrC': 'b0004',\n",
       " 'ilvA': 'b3772',\n",
       " 'trpC': 'b1262',\n",
       " 'pheA': 'b2599',\n",
       " 'tyrA': 'b2600',\n",
       " 'hisB': 'b2022',\n",
       " 'proA': 'b0243',\n",
       " 'argA': 'b2818',\n",
       " 'leuB': 'b0073'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all the pairwise knockouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "knockouts=set()\n",
    "for i in combinations(knockouts_gene_names,2):\n",
    "    if set(i) not in knockouts:\n",
    "        knockouts.add(frozenset(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_knockouts=[tuple(i) for i in knockouts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:54\u001b[0;36m\u001b[0m\n\u001b[0;31m    for agent in env.agents:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "for ko in unique_knockouts:\n",
    "    model1 = model_base.copy()\n",
    "    model2 = model_base.copy()\n",
    "    model1.remove_reactions(model1.genes.get_by_id(gene_ids[ko[0]]).reactions)\n",
    "    model2.remove_reactions(model2.genes.get_by_id(gene_ids[ko[1]]).reactions)\n",
    "    ko_name = ko[0] + \"_\" + ko[1]\n",
    "    agent1 = tk.Agent(\n",
    "        \"agent1\",\n",
    "        model=model1,\n",
    "        actor_network=tk.NN,\n",
    "        critic_network=tk.NN,\n",
    "        clip=0.1,\n",
    "        lr_actor=0.0001,\n",
    "        lr_critic=0.001,\n",
    "        grad_updates=1,\n",
    "        optimizer_actor=torch.optim.Adam,\n",
    "        optimizer_critic=torch.optim.Adam,\n",
    "        observables=[\"agent1\", \"agent2\", \"glucose\", \"A\", \"B\"],\n",
    "        actions=[\"EX_A_sp1\", \"EX_B_sp1\"],\n",
    "        gamma=1,\n",
    "    )\n",
    "    agent2 = tk.Agent(\n",
    "        \"agent2\",\n",
    "        model=model2,\n",
    "        actor_network=tk.NN,\n",
    "        critic_network=tk.NN,\n",
    "        clip=0.1,\n",
    "        lr_actor=0.0001,\n",
    "        lr_critic=0.001,\n",
    "        grad_updates=1,\n",
    "        optimizer_actor=torch.optim.Adam,\n",
    "        optimizer_critic=torch.optim.Adam,\n",
    "        observables=[\"agent1\", \"agent2\", \"glucose\", \"A\", \"B\"],\n",
    "        actions=[\"EX_A_sp2\", \"EX_B_sp2\"],\n",
    "        gamma=1,\n",
    "    )\n",
    "\n",
    "    env = tk.Environment(\n",
    "        ko_name,\n",
    "        agents=[agent1, agent2],\n",
    "        dilution_rate=0,\n",
    "        extracellular_reactions=[],\n",
    "        initial_condition={},\n",
    "        inlet_conditions={},\n",
    "        max_c={},\n",
    "        dt=0.1,\n",
    "        episode_time=100,  ##TOBECHANGED\n",
    "        number_of_batches=2000,  ##TOBECHANGED\n",
    "        batch_size=NUM_CORES,\n",
    "    )\n",
    "\n",
    "    env.rewards = {agent.name: [] for agent in env.agents}\n",
    "\n",
    "    if not os.path.exists(f\"Results/{env.name}\"):\n",
    "        os.makedirs(f\"Results/{env.name}\")\n",
    "    for batch in range(env.number_of_batches):\n",
    "\n",
    "        batch_obs, batch_acts, batch_log_probs, batch_rtgs = tk.rollout(env)\n",
    "\n",
    "    for agent in env.agents:\n",
    "        V, _ = agent.evaluate(batch_obs[agent.name], batch_acts[agent.name])\n",
    "        A_k = batch_rtgs[agent.name] - V.detach()\n",
    "        A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-5)\n",
    "        for _ in range(agent.grad_updates):\n",
    "            V, curr_log_probs = agent.evaluate(\n",
    "                batch_obs[agent.name], batch_acts[agent.name]\n",
    "            )\n",
    "            ratios = torch.exp(curr_log_probs - batch_log_probs[agent.name])\n",
    "            surr1 = ratios * A_k.detach()\n",
    "            surr2 = torch.clamp(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "            actor_loss = (-torch.min(surr1, surr2)).mean()\n",
    "            critic_loss = nn.MSELoss()(V, batch_rtgs[agent.name])\n",
    "            agent.optimizer_policy_.zero_grad()\n",
    "            actor_loss.backward(retain_graph=False)\n",
    "            agent.optimizer_policy_.step()\n",
    "            agent.optimizer_value_.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            agent.optimizer_value_.step()\n",
    "\n",
    "    if batch % 200 == 0:\n",
    "        for agent in env.agents:\n",
    "            with open(f\"Results/{env.name}/{agent.name}_{batch}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(agent, f)\n",
    "        with open(f\"Results/{env.name}/returns_{batch}.json\", \"w\") as f:\n",
    "            json.dump(env.rewards, f)\n",
    "\n",
    "    print(f\"Batch {batch} finished:\")\n",
    "    for agent in env.agents:\n",
    "        print(\n",
    "            f\"{agent.name} return is:  {np.mean(env.rewards[agent.name][-env.episodes_per_batch:])}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "DictList has no attribute or entry names",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/cobra/core/dictlist.py:526\u001b[0m, in \u001b[0;36mDictList.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     \u001b[39mreturn\u001b[39;00m DictList\u001b[39m.\u001b[39;49mget_by_id(\u001b[39mself\u001b[39;49m, attr)\n\u001b[1;32m    527\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/cobra/core/dictlist.py:74\u001b[0m, in \u001b[0;36mDictList.get_by_id\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m\"\"\"Return the element with a matching id.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dict[\u001b[39mid\u001b[39;49m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'names'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Ecoli_aux.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/parsaghadermarzi/Desktop/Academics/Projects/Reinforcement_Learning_Modeling/PPO/Ecoli_aux.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model1\u001b[39m.\u001b[39;49mgenes\u001b[39m.\u001b[39;49mnames\n",
      "File \u001b[0;32m~/.pyenv/versions/miniforge3-4.10.3-10/lib/python3.9/site-packages/cobra/core/dictlist.py:528\u001b[0m, in \u001b[0;36mDictList.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[39mreturn\u001b[39;00m DictList\u001b[39m.\u001b[39mget_by_id(\u001b[39mself\u001b[39m, attr)\n\u001b[1;32m    527\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 528\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDictList has no attribute or entry \u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: DictList has no attribute or entry names"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd4282f6964f11bb4427604f51fdde6c3d4aaf7297d931ff306d1c282a07f33e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
